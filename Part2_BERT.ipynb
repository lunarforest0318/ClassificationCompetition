{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Part2_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzCetP638N38"
      },
      "source": [
        "## **0. Mount the Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY84p-248QKJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1c3b234-bdfa-4c82-f7d8-d7ad3ed5532a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNS_zScH8eEc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3e2f46e-b695-4a8a-ae0a-24de819125eb"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/Deep Learning/CS410_Final')\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " answer.txt  'Copy of answer.txt'   data   models   prob.txt   stopwords.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK_4rfGg9ew2"
      },
      "source": [
        "## Reference Tutorials:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYOy_J_XF71Z"
      },
      "source": [
        "Some of the codes below are from this tutorial with some customization for this project:\n",
        "https://colab.research.google.com/drive/1ywsvwO6thOVOrfagjjfuxEf6xVRxbUNO#scrollTo=6J-FYdx6nFE_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htUNJpzioMJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11c25efc-4b9e-463e-e521-6a8fa7ade301"
      },
      "source": [
        "!pip install pytorch-pretrained-bert pytorch-nlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 18.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 12.7MB/s \n",
            "\u001b[?25hCollecting pytorch-nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl (90kB)\n",
            "\r\u001b[K     |███▋                            | 10kB 18.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 20kB 26.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30kB 25.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 40kB 28.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 51kB 26.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 61kB 22.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 71kB 23.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 81kB 24.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/9c/544396572c05841b7a2482c88be5dd54dcd18ba97abeb1e8d34daf921a54/boto3-1.16.30-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 41.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Collecting botocore<1.20.0,>=1.19.30\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/a3/1ee497faf994d180df5d14d456eef1ef46ca1ffce617816faa4ff8164608/botocore-1.19.30-py2.py3-none-any.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 47.7MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.1MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.30->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.30->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "\u001b[31mERROR: botocore 1.19.30 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert, pytorch-nlp\n",
            "Successfully installed boto3-1.16.30 botocore-1.19.30 jmespath-0.10.0 pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI1POhmm7js0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a754353a-c20c-49fc-a784-79e0b0ed21aa"
      },
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import torch.optim as optim\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "# specify GPU device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYO29zLUtsFF"
      },
      "source": [
        "## BERT Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tazUtEWAqscu"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1ngAPYIra9j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fa934bb-e652-4dd7-e9d1-53cacff16695"
      },
      "source": [
        "documents_path= 'data/train.jsonl'\n",
        "df = pd.read_json(documents_path,lines=True)\n",
        "# create sample and label list\n",
        "sentences = df.response.values\n",
        "# add special tokens at the beginning and end of each sentence for BERT to work properly\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "labels = df.label.values \n",
        "labels=np.where(labels=='SARCASM', 1, labels) \n",
        "labels=np.where(labels=='NOT_SARCASM', 0, labels) \n",
        "\n",
        "#Use this line for bert base model\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)\n",
        "tokenized_texts2 = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "#Remove stopwords\n",
        "stop_word = open(\"stopwords.txt\", \"r\")\n",
        "stop_word = stop_word.read().splitlines()    \n",
        "stop_word.append('@')\n",
        "stop_word.append('user')\n",
        "\n",
        "tokenized_texts=[]\n",
        "for sublist in tokenized_texts2: \n",
        "    ele=[]\n",
        "    for word in sublist: \n",
        "        if not word in stop_word:\n",
        "            ele.append(word)\n",
        "    tokenized_texts.append(ele)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 16662918.80B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWpLgBGpKqRu"
      },
      "source": [
        "## Set up BERT Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0tzo3si-2hG"
      },
      "source": [
        "# Set the maximum sequence length. \n",
        "def max_seq_len():\n",
        "    maxl=0\n",
        "    for i in range(5000):\n",
        "        if len(tokenized_texts[i]) > maxl:\n",
        "            maxl = len(tokenized_texts[i])\n",
        "    print (maxl)\n",
        "\n",
        "#The longest sequence in our training set is 74, but we'll leave some room so set up at 128\n",
        "MAX_LEN = 128\n",
        "\n",
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=10, test_size=0.2)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids, random_state=10, test_size=0.2)\n",
        "train_labels=train_labels.astype(float)\n",
        "validation_labels=validation_labels.astype(float)\n",
        "\n",
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels,dtype=torch.long)\n",
        "validation_labels = torch.tensor(validation_labels,dtype=torch.long)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "\n",
        "# Select a batch size for training.\n",
        "batch_size = 16\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yghvRUPQFB5k"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDWPnnFmEfsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1c051c0-50c1-46ca-fdb2-7bc4bdff1ed1"
      },
      "source": [
        "#Use this line for bert base model\n",
        "#model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-large-uncased\", num_labels=2)\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1248501532/1248501532 [00:21<00:00, 57524814.78B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKnLdwNQFR5V"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OrVAXsHFD5M"
      },
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.001},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVzMaGSmFD71"
      },
      "source": [
        "# Instead of using the default optimizer BertAdam, I use the Adam optimizer in the torch library with tuning parameters\n",
        "# It turns out that it performs better than BertAdam \n",
        "#optimizer = BertAdam(optimizer_grouped_parameters, lr=2e-5, warmup=.1)\n",
        "optimizer = optim.Adam(optimizer_grouped_parameters, lr=5e-6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rddzEnRbFuBw"
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    tp,fp,fn = 0,0,0\n",
        "    for i in range(len(labels_flat)):\n",
        "        if pred_flat[i] == 1 and labels_flat[i]==1:\n",
        "            tp += 1\n",
        "        elif pred_flat[i] == 1 and labels_flat[i]==0:\n",
        "            fp += 1\n",
        "        elif pred_flat[i] == 0 and labels_flat[i]==1:\n",
        "            fn += 1  \n",
        "    return tp,fp,fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy7bohOvFuMc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5088a738-6334-4926-c771-437d2319700e"
      },
      "source": [
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 50\n",
        "t = [] \n",
        "train_loss_set = []\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "  # Training\n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "  \n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "    train_loss_set.append(loss.item())    \n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    \n",
        " \n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "  \n",
        "  #Save the model so we don't need to retrain the model every time\n",
        "  #Save the model\n",
        "  PATH=\"models/BERT_Best_2020Nov8\"\n",
        "  torch.save(model.state_dict(), PATH)\n",
        "    \n",
        "  # Validation\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "  eval_tp, eval_fp, eval_fn = 0, 0, 0\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    \n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tp,fp,fn = flat_accuracy(logits, label_ids)\n",
        "    \n",
        "    #eval_accuracy += tmp_eval_accuracy\n",
        "    #nb_eval_steps += 1\n",
        "\n",
        "    eval_tp += tp\n",
        "    eval_fp += fp\n",
        "    eval_fn += fn\n",
        " \n",
        "    precision,recall,f1 = 0,0,0\n",
        "    precision = eval_tp / (eval_tp + eval_fp + 0.01)\n",
        "    recall = eval_tp / (eval_tp + eval_fn + 0.01)\n",
        "    F1 = 2*precision*recall / (precision + recall + 0.01)\n",
        "\n",
        "  print(\"Validation F1 Score: {}\".format(F1))\n",
        "  print(\"Validation Precision Score: {}\".format(precision))\n",
        "  print(\"Validation Recall Score: {}\".format(recall))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/50 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.5876763174533844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   2%|▏         | 1/50 [06:28<5:16:56, 388.09s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7676154146052888\n",
            "Validation Precision Score: 0.7133214446425893\n",
            "Validation Recall Score: 0.8425031003326706\n",
            "Train loss: 0.4934219738841057\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   4%|▍         | 2/50 [12:36<5:05:42, 382.13s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7572917437925312\n",
            "Validation Precision Score: 0.7457486676333779\n",
            "Validation Recall Score: 0.7795122143264896\n",
            "Train loss: 0.43972327530384064\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   6%|▌         | 3/50 [18:44<4:56:04, 377.96s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7908923918181269\n",
            "Validation Precision Score: 0.7147223397752387\n",
            "Validation Recall Score: 0.897620125588079\n",
            "Train loss: 0.36706029322743416\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   8%|▊         | 4/50 [24:52<4:47:31, 375.04s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7838869870770107\n",
            "Validation Precision Score: 0.7696485084548979\n",
            "Validation Recall Score: 0.809039192141887\n",
            "Train loss: 0.29103702755272387\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  10%|█         | 5/50 [31:01<4:39:48, 373.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7950264862763408\n",
            "Validation Precision Score: 0.7647977594657187\n",
            "Validation Recall Score: 0.8385661699572843\n",
            "Train loss: 0.22231739746034146\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  12%|█▏        | 6/50 [37:09<4:32:32, 371.66s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7890751439492195\n",
            "Validation Precision Score: 0.7987888687476346\n",
            "Validation Recall Score: 0.7893545402649554\n",
            "Train loss: 0.15829105029255153\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  14%|█▍        | 7/50 [43:18<4:25:41, 370.72s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7985016991526213\n",
            "Validation Precision Score: 0.7904611340736367\n",
            "Validation Recall Score: 0.8169130528926596\n",
            "Train loss: 0.10934291379898786\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  16%|█▌        | 8/50 [49:26<4:19:00, 370.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7890166740320981\n",
            "Validation Precision Score: 0.8068941688177069\n",
            "Validation Recall Score: 0.7814806795141828\n",
            "Train loss: 0.07651696697901934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  18%|█▊        | 9/50 [55:35<4:12:38, 369.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.8154950175366841\n",
            "Validation Precision Score: 0.7777640605985785\n",
            "Validation Recall Score: 0.8680931477726817\n",
            "Train loss: 0.061865175793878735\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  20%|██        | 10/50 [1:01:44<4:06:14, 369.36s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7765629450337569\n",
            "Validation Precision Score: 0.8158283548532151\n",
            "Validation Recall Score: 0.7499852365110923\n",
            "Train loss: 0.048712983450852336\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  22%|██▏       | 11/50 [1:07:52<3:59:56, 369.14s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7806652606299842\n",
            "Validation Precision Score: 0.8201109183957517\n",
            "Validation Recall Score: 0.7539221668864786\n",
            "Train loss: 0.048557110268156976\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  24%|██▍       | 12/50 [1:14:01<3:53:41, 368.98s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.8059314824666085\n",
            "Validation Precision Score: 0.8030732997432483\n",
            "Validation Recall Score: 0.8188815180803528\n",
            "Train loss: 0.030030351085821166\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  26%|██▌       | 13/50 [1:20:09<3:47:27, 368.86s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7981803504311857\n",
            "Validation Precision Score: 0.8071410111130991\n",
            "Validation Recall Score: 0.7991968662034212\n",
            "Train loss: 0.02977936734049581\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  28%|██▊       | 14/50 [1:26:18<3:41:15, 368.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7874316690772712\n",
            "Validation Precision Score: 0.8036274569340702\n",
            "Validation Recall Score: 0.7814806795141828\n",
            "Train loss: 0.02735841214703396\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  30%|███       | 15/50 [1:32:26<3:35:01, 368.62s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.8137192184758594\n",
            "Validation Precision Score: 0.7793455632462056\n",
            "Validation Recall Score: 0.8621877522096022\n",
            "Train loss: 0.02516504549444653\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  32%|███▏      | 16/50 [1:38:35<3:28:55, 368.68s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7950157279876172\n",
            "Validation Precision Score: 0.808836844329088\n",
            "Validation Recall Score: 0.7913230054526486\n",
            "Train loss: 0.028895493095740677\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  34%|███▍      | 17/50 [1:44:45<3:23:01, 369.14s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.766194729112741\n",
            "Validation Precision Score: 0.8218079775506114\n",
            "Validation Recall Score: 0.7263636542587745\n",
            "Train loss: 0.014778021763195284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  36%|███▌      | 18/50 [1:50:54<3:16:48, 369.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.8039394450288937\n",
            "Validation Precision Score: 0.7973078908625074\n",
            "Validation Recall Score: 0.8208499832680459\n",
            "Train loss: 0.01639224299835041\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  38%|███▊      | 19/50 [1:57:02<3:10:34, 368.86s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7877389084797559\n",
            "Validation Precision Score: 0.8149518721024511\n",
            "Validation Recall Score: 0.771638353575717\n",
            "Train loss: 0.017980043251707684\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  40%|████      | 20/50 [2:03:11<3:04:25, 368.86s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7474675042581179\n",
            "Validation Precision Score: 0.8258629208724501\n",
            "Validation Recall Score: 0.6909312808802976\n",
            "Train loss: 0.02629626293241745\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  42%|████▏     | 21/50 [2:09:20<2:58:16, 368.86s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.8009556384383746\n",
            "Validation Precision Score: 0.8107408218959782\n",
            "Validation Recall Score: 0.8011653313911143\n",
            "Train loss: 0.013000565610913327\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  44%|████▍     | 22/50 [2:15:30<2:52:14, 369.09s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7867787344352059\n",
            "Validation Precision Score: 0.8311508408908899\n",
            "Validation Recall Score: 0.7558906320741717\n",
            "Train loss: 0.014684231530758552\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  46%|████▌     | 23/50 [2:21:39<2:46:10, 369.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.8156826016068726\n",
            "Validation Precision Score: 0.7845460584190589\n",
            "Validation Recall Score: 0.8602192870219091\n",
            "Train loss: 0.010048861105431569\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  48%|████▊     | 24/50 [2:27:49<2:40:01, 369.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.817584217461741\n",
            "Validation Precision Score: 0.7752478179822652\n",
            "Validation Recall Score: 0.8759670085234543\n",
            "Train loss: 0.011505542488215724\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|█████     | 25/50 [2:33:58<2:33:54, 369.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7966027038250636\n",
            "Validation Precision Score: 0.8079838403231936\n",
            "Validation Recall Score: 0.7952599358280349\n",
            "Train loss: 0.01165980835193477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  52%|█████▏    | 26/50 [2:40:08<2:27:49, 369.57s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7993206057327951\n",
            "Validation Precision Score: 0.7995953386120893\n",
            "Validation Recall Score: 0.809039192141887\n",
            "Train loss: 0.017487711220484925\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  54%|█████▍    | 27/50 [2:46:18<2:21:40, 369.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7840125121652829\n",
            "Validation Precision Score: 0.8181645208346546\n",
            "Validation Recall Score: 0.7617960276372513\n",
            "Train loss: 0.0055440847617865075\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  56%|█████▌    | 28/50 [2:52:28<2:15:31, 369.63s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7857167842137712\n",
            "Validation Precision Score: 0.8128729132450468\n",
            "Validation Recall Score: 0.7696698883880239\n",
            "Train loss: 0.013788968366920017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  58%|█████▊    | 29/50 [2:58:38<2:09:28, 369.92s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7913889994883168\n",
            "Validation Precision Score: 0.8160988409330386\n",
            "Validation Recall Score: 0.7775437491387965\n",
            "Train loss: 0.015440815810259665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  60%|██████    | 30/50 [3:04:48<2:03:17, 369.85s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7861386599399792\n",
            "Validation Precision Score: 0.8115774000538292\n",
            "Validation Recall Score: 0.771638353575717\n",
            "Train loss: 0.01017964690394001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  62%|██████▏   | 31/50 [3:10:58<1:57:05, 369.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.8033152379634737\n",
            "Validation Precision Score: 0.8114918354794548\n",
            "Validation Recall Score: 0.8051022617665007\n",
            "Train loss: 0.014173782623416628\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  64%|██████▍   | 32/50 [3:17:07<1:50:54, 369.68s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.8052914089798304\n",
            "Validation Precision Score: 0.813475923096764\n",
            "Validation Recall Score: 0.8070707269541938\n",
            "Train loss: 0.00639172316143231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  66%|██████▌   | 33/50 [3:23:16<1:44:41, 369.52s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.789372989696823\n",
            "Validation Precision Score: 0.8140327679180183\n",
            "Validation Recall Score: 0.7755752839511033\n",
            "Train loss: 0.012820464978780364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  68%|██████▊   | 34/50 [3:29:25<1:38:28, 369.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7726914085825743\n",
            "Validation Precision Score: 0.8191542667915732\n",
            "Validation Recall Score: 0.7401429105726265\n",
            "Train loss: 0.00963111943997501\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  70%|███████   | 35/50 [3:35:34<1:32:17, 369.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.8137192184758594\n",
            "Validation Precision Score: 0.7793455632462056\n",
            "Validation Recall Score: 0.8621877522096022\n",
            "Train loss: 0.011173322410570109\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  72%|███████▏  | 36/50 [3:41:43<1:26:06, 369.05s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.8131978602735148\n",
            "Validation Precision Score: 0.8041672211554913\n",
            "Validation Recall Score: 0.8326607743942048\n",
            "Train loss: 0.003605348839351791\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  74%|███████▍  | 37/50 [3:47:51<1:19:55, 368.90s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.8093864788768705\n",
            "Validation Precision Score: 0.8258942126677598\n",
            "Validation Recall Score: 0.8031337965788076\n",
            "Train loss: 0.0037206539220860577\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  76%|███████▌  | 38/50 [3:54:00<1:13:47, 368.92s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.8096884290044543\n",
            "Validation Precision Score: 0.7992272873619818\n",
            "Validation Recall Score: 0.8306923092065117\n",
            "Train loss: 0.008655681198149977\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  78%|███████▊  | 39/50 [4:00:09<1:07:36, 368.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.8075150142451267\n",
            "Validation Precision Score: 0.8061859266293289\n",
            "Validation Recall Score: 0.8188815180803528\n",
            "Train loss: 0.009301619400139316\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  80%|████████  | 40/50 [4:06:17<1:01:27, 368.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7437116753017633\n",
            "Validation Precision Score: 0.8369626043161967\n",
            "Validation Recall Score: 0.6771520245664455\n",
            "Train loss: 0.014453783535849652\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  82%|████████▏ | 41/50 [4:12:26<55:19, 368.83s/it]  "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7608644551475591\n",
            "Validation Precision Score: 0.8249812504261267\n",
            "Validation Recall Score: 0.7145528631326156\n",
            "Train loss: 0.004195711722539272\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  84%|████████▍ | 42/50 [4:18:35<49:09, 368.73s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.8035272282831154\n",
            "Validation Precision Score: 0.7946616984467976\n",
            "Validation Recall Score: 0.822818448455739\n",
            "Train loss: 0.007016771192469605\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  86%|████████▌ | 43/50 [4:24:43<43:00, 368.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.8064095933937101\n",
            "Validation Precision Score: 0.8097880433716986\n",
            "Validation Recall Score: 0.8129761225172732\n",
            "Train loss: 0.005585929510867572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  88%|████████▊ | 44/50 [4:30:52<36:51, 368.64s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.8103296815883038\n",
            "Validation Precision Score: 0.7932813169214726\n",
            "Validation Recall Score: 0.8385661699572843\n",
            "Train loss: 0.006265895185242698\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  90%|█████████ | 45/50 [4:37:01<30:43, 368.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.826682391817365\n",
            "Validation Precision Score: 0.7806428213675066\n",
            "Validation Recall Score: 0.8897462648373063\n",
            "Train loss: 0.0013423664586152881\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  92%|█████████▏| 46/50 [4:43:10<24:34, 368.73s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.8142479774079204\n",
            "Validation Precision Score: 0.800736828255108\n",
            "Validation Recall Score: 0.8385661699572843\n",
            "Train loss: 0.008718710718705551\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  94%|█████████▍| 47/50 [4:49:18<18:26, 368.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7958221609389537\n",
            "Validation Precision Score: 0.8189131910866032\n",
            "Validation Recall Score: 0.783449144701876\n",
            "Train loss: 0.004572732045562589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  96%|█████████▌| 48/50 [4:55:27<12:17, 368.64s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.788541478314779\n",
            "Validation Precision Score: 0.8166496531322265\n",
            "Validation Recall Score: 0.771638353575717\n",
            "Train loss: 0.010786418569172384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  98%|█████████▊| 49/50 [5:01:36<06:08, 368.72s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7989559558171727\n",
            "Validation Precision Score: 0.8047178556635964\n",
            "Validation Recall Score: 0.8031337965788076\n",
            "Train loss: 0.004661065662927285\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 50/50 [5:07:44<00:00, 369.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation F1 Score: 0.7688271247013221\n",
            "Validation Precision Score: 0.8355973607908496\n",
            "Validation Recall Score: 0.720458258695695\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHk_WRbt1N_H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "805f4a22-4773-4a07-a443-dc1acb077aba"
      },
      "source": [
        "#Evaluation\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(train_loss_set)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjNx_1mMluyx"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxb2SEHHluKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5c8d5e5-d661-415a-c6ed-4b85c0114f12"
      },
      "source": [
        "#Load model\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-large-uncased\", num_labels=2)\n",
        "PATH=\"models/BERT_Best_2020Nov8\"\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.cuda()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgY5VVMOFuUj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDk6XSYEKKQU"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxjKFdnPFuXa"
      },
      "source": [
        "test_document_path = 'data/test.jsonl'\n",
        "MAX_LEN = 128\n",
        "batch_size=16\n",
        "def prediction_prep(test_document_path):\n",
        "    df = pd.read_json(test_document_path, lines=True)\n",
        "    sentences = df.response.values\n",
        "    sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)\n",
        "    tokenized_texts2 = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "    stop_word = open(\"stopwords.txt\", \"r\")\n",
        "    stop_word = stop_word.read().splitlines()    \n",
        "    stop_word.append('@')\n",
        "    stop_word.append('user')\n",
        "    tokenized_texts=[]\n",
        "    for sublist in tokenized_texts2: \n",
        "        ele=[]\n",
        "        for word in sublist: \n",
        "            if not word in stop_word:\n",
        "                ele.append(word)\n",
        "        tokenized_texts.append(ele)\n",
        "\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "    attention_masks = []\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i>0) for i in seq]\n",
        "        attention_masks.append(seq_mask) \n",
        "\n",
        "    prediction_inputs = torch.tensor(input_ids)\n",
        "    prediction_masks = torch.tensor(attention_masks)\n",
        "    prediction_data = TensorDataset(prediction_inputs, prediction_masks)\n",
        "    prediction_sampler = SequentialSampler(prediction_data)\n",
        "    prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
        "\n",
        "    # Predict \n",
        "    model.eval()\n",
        "    predictions=[]\n",
        "\n",
        "    for batch in prediction_dataloader:\n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      # Unpack the inputs from our dataloader\n",
        "      b_input_ids, b_input_mask = batch\n",
        "      # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n",
        "      with torch.no_grad():\n",
        "        # Forward pass, calculate logit predictions\n",
        "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "      # Move logits and labels to CPU\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "\n",
        "      # Store predictions and true labels\n",
        "      predictions.append(logits)\n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w89IUDS_To9n"
      },
      "source": [
        "def generate_output(predictions):\n",
        "    res=[]; odd=[]\n",
        "    for pred in predictions:\n",
        "       odd.append(pred[:,0].flatten()) \n",
        "    odd=np.concatenate(odd).ravel()\n",
        "    #convert logit to probability\n",
        "    odd=np.exp(odd)\n",
        "    prob=odd/(1+odd)\n",
        "    \n",
        "    #Set threshold\n",
        "    thresh = 0.8\n",
        "    for i in range(len(prob)):\n",
        "        if prob[i] > thresh:\n",
        "            res.append('NOT_SARCASM')\n",
        "        else:\n",
        "            res.append('SARCASM')\n",
        "\n",
        "    twitter_id=[]\n",
        "    for i in range(1800):\n",
        "        twitter_id.append('twitter_' + str(i+1))\n",
        "\n",
        "    results = zip(twitter_id,res)\n",
        "    res2=[]\n",
        "    for i ,j in results:\n",
        "        res2.append(str(i)+','+str(j))\n",
        " \n",
        "    with open('answer.txt', 'w') as filehandle:\n",
        "        filehandle.writelines(\"%s\\n\" % place for place in res2)\n",
        "\n",
        "    with open('prob.txt', 'w') as filehandle:\n",
        "        filehandle.writelines(\"%s\\n\" % place for place in prob)\n",
        " \n",
        "predictions=prediction_prep(test_document_path)\n",
        "generate_output(predictions)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}